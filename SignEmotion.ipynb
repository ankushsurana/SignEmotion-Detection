{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d8ef7ab-66ea-459b-974e-760714c0e578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\ankush\\anaconda3\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\ankush\\anaconda3\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\ankush\\anaconda3\\lib\\site-packages (3.8.4)\n",
      "Requirement already satisfied: seaborn in c:\\users\\ankush\\anaconda3\\lib\\site-packages (0.13.2)\n",
      "Requirement already satisfied: tensorflow in c:\\users\\ankush\\anaconda3\\lib\\site-packages (2.18.0)\n",
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.10.0.84-cp37-abi3-win_amd64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\ankush\\anaconda3\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\ankush\\anaconda3\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\ankush\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\ankush\\anaconda3\\lib\\site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\ankush\\anaconda3\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\ankush\\anaconda3\\lib\\site-packages (from matplotlib) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\ankush\\anaconda3\\lib\\site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\ankush\\anaconda3\\lib\\site-packages (from matplotlib) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\ankush\\anaconda3\\lib\\site-packages (from matplotlib) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\ankush\\anaconda3\\lib\\site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: tensorflow-intel==2.18.0 in c:\\users\\ankush\\anaconda3\\lib\\site-packages (from tensorflow) (2.18.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\ankush\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\ankush\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\ankush\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (24.12.23)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\ankush\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\ankush\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\ankush\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\ankush\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\ankush\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.20.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\ankush\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.32.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\ankush\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (75.5.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\ankush\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\ankush\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\ankush\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (4.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\ankush\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\ankush\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.68.1)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in c:\\users\\ankush\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\users\\ankush\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.7.0)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\ankush\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.12.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in c:\\users\\ankush\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.4.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\ankush\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.18.0->tensorflow) (0.45.0)\n",
      "Requirement already satisfied: rich in c:\\users\\ankush\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (13.3.5)\n",
      "Requirement already satisfied: namex in c:\\users\\ankush\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\ankush\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.13.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ankush\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ankush\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ankush\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ankush\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2024.8.30)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\ankush\\anaconda3\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\ankush\\anaconda3\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\ankush\\anaconda3\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\ankush\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in c:\\users\\ankush\\anaconda3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\ankush\\anaconda3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\ankush\\anaconda3\\lib\\site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.1.0)\n",
      "Downloading opencv_python-4.10.0.84-cp37-abi3-win_amd64.whl (38.8 MB)\n",
      "   ---------------------------------------- 0.0/38.8 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 2.6/38.8 MB 13.7 MB/s eta 0:00:03\n",
      "   -- ------------------------------------- 2.6/38.8 MB 13.7 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 5.0/38.8 MB 8.2 MB/s eta 0:00:05\n",
      "   ------ --------------------------------- 6.0/38.8 MB 7.4 MB/s eta 0:00:05\n",
      "   ------- -------------------------------- 6.8/38.8 MB 6.7 MB/s eta 0:00:05\n",
      "   ------- -------------------------------- 7.3/38.8 MB 5.9 MB/s eta 0:00:06\n",
      "   -------- ------------------------------- 7.9/38.8 MB 5.6 MB/s eta 0:00:06\n",
      "   -------- ------------------------------- 8.7/38.8 MB 5.4 MB/s eta 0:00:06\n",
      "   --------- ------------------------------ 9.7/38.8 MB 5.3 MB/s eta 0:00:06\n",
      "   ----------- ---------------------------- 11.0/38.8 MB 5.3 MB/s eta 0:00:06\n",
      "   ------------ --------------------------- 12.3/38.8 MB 5.4 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 13.1/38.8 MB 5.3 MB/s eta 0:00:05\n",
      "   -------------- ------------------------- 14.2/38.8 MB 5.2 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 14.9/38.8 MB 5.2 MB/s eta 0:00:05\n",
      "   ---------------- ----------------------- 15.7/38.8 MB 5.1 MB/s eta 0:00:05\n",
      "   ----------------- ---------------------- 16.8/38.8 MB 5.1 MB/s eta 0:00:05\n",
      "   ------------------ --------------------- 18.4/38.8 MB 5.2 MB/s eta 0:00:04\n",
      "   -------------------- ------------------- 19.9/38.8 MB 5.3 MB/s eta 0:00:04\n",
      "   --------------------- ------------------ 20.7/38.8 MB 5.3 MB/s eta 0:00:04\n",
      "   --------------------- ------------------ 21.0/38.8 MB 5.1 MB/s eta 0:00:04\n",
      "   ---------------------- ----------------- 21.8/38.8 MB 5.0 MB/s eta 0:00:04\n",
      "   ----------------------- ---------------- 23.1/38.8 MB 5.0 MB/s eta 0:00:04\n",
      "   ------------------------- -------------- 24.4/38.8 MB 5.1 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 25.4/38.8 MB 5.1 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 26.2/38.8 MB 5.1 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 27.5/38.8 MB 5.1 MB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 28.6/38.8 MB 5.1 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 29.4/38.8 MB 5.1 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 30.7/38.8 MB 5.1 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 32.5/38.8 MB 5.2 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 33.3/38.8 MB 5.2 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 33.8/38.8 MB 5.1 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 34.6/38.8 MB 5.1 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 35.7/38.8 MB 5.0 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 36.4/38.8 MB 5.0 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 37.7/38.8 MB 5.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 38.8/38.8 MB 5.0 MB/s eta 0:00:00\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.10.0.84\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install numpy pandas matplotlib seaborn tensorflow opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21dbc55b-5c10-42ec-95e9-a6150092dfc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Dense, Flatten, MaxPooling2D, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler, ReduceLROnPlateau\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from tensorflow.keras.regularizers import l1, l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4663836a-ac01-4123-9e41-9bc28ee2d3c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset shape: (27455, 28, 28, 1), Labels shape: (27455, 24)\n",
      "Testing dataset shape: (7172, 28, 28, 1), Labels shape: (7172, 24)\n",
      "Data Augmentation Applied to Sign Language Dataset\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "sign_minist_train = pd.read_csv(r\"D:\\MCA project\\Extra Projects\\Sign\\sign_mnist_train\\sign_mnist_train.csv\")\n",
    "sign_minist_test = pd.read_csv(r\"D:\\MCA project\\Extra Projects\\Sign\\sign_mnist_test\\sign_mnist_test.csv\")\n",
    "\n",
    "X_train_sign = sign_minist_train.drop('label', axis=1).values.reshape(-1, 28, 28, 1)\n",
    "y_train_sign = to_categorical(sign_minist_train['label'] - 1, num_classes=24)\n",
    "\n",
    "X_test_sign = sign_minist_test.drop('label', axis=1).values.reshape(-1, 28, 28, 1)\n",
    "y_test_sign = to_categorical(sign_minist_test['label'] - 1, num_classes=24)\n",
    "\n",
    "# Normalize the dataset\n",
    "X_train_sign = X_train_sign / 255.0\n",
    "X_test_sign = X_test_sign / 255.0\n",
    "\n",
    "# Check the shape of the datasets\n",
    "print(f\"Training dataset shape: {X_train_sign.shape}, Labels shape: {y_train_sign.shape}\")\n",
    "print(f\"Testing dataset shape: {X_test_sign.shape}, Labels shape: {y_test_sign.shape}\")\n",
    "\n",
    "# Augment Sign Language data\n",
    "datagen_sign = ImageDataGenerator(\n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "datagen_sign = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "datagen_sign.fit(X_train_sign)\n",
    "# datagen_sign.flow()\n",
    "\n",
    "print(\"Data Augmentation Applied to Sign Language Dataset\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e4df2dc-6590-4b8d-b1fd-5f62ad026619",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emotion Detection Dataset Loaded and Preprocessed\n",
      "x_train_fer shape: (28709, 48, 48, 1), y_train_fer shape: (28709, 7)\n",
      "x_test_fer shape: (3589, 48, 48, 1), y_test_fer shape: (3589, 7)\n"
     ]
    }
   ],
   "source": [
    "# Load emotion dataset\n",
    "trainingset = np.loadtxt(r\"D:\\MCA project\\Extra Projects\\fer2013_training_onehot.csv\", delimiter=',')\n",
    "testingset = np.loadtxt(r\"D:\\MCA project\\Extra Projects\\fer2013_publictest_onehot.csv\", delimiter=',')\n",
    "\n",
    "# Extract pixels and labels\n",
    "pixels = trainingset['pixels'].apply(lambda pixel_sequence: np.array(pixel_sequence.split(), dtype=np.uint8))\n",
    "labels = trainingset['emotion']\n",
    "\n",
    "\n",
    "# Split the data into input and output\n",
    "x_train_fer = trainingset[:, :-7]\n",
    "y_train_fer = trainingset[:, -7:]\n",
    "x_test_fer = testingset[:, :-7]\n",
    "y_test_fer = testingset[:, -7:]\n",
    "\n",
    "# Reshape the input data\n",
    "x_train_fer = x_train_fer.reshape(-1, 48, 48, 1)\n",
    "x_test_fer = x_test_fer.reshape(-1, 48, 48, 1)\n",
    "\n",
    "# Normalize the dataset\n",
    "x_train_fer = x_train_fer / 255.0\n",
    "x_test_fer = x_test_fer / 255.0\n",
    "\n",
    "print(\"Emotion Detection Dataset Loaded and Preprocessed\")\n",
    "print(f\"x_train_fer shape: {x_train_fer.shape}, y_train_fer shape: {y_train_fer.shape}\")\n",
    "print(f\"x_test_fer shape: {x_test_fer.shape}, y_test_fer shape: {y_test_fer.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bfc1de86-17d4-40d4-9d9b-046b957e486f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ankush\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\input_layer.py:27: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 82ms/step - accuracy: 0.7908 - loss: 0.7367 - val_accuracy: 0.7054 - val_loss: 0.9541\n",
      "Epoch 2/10\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 79ms/step - accuracy: 0.9841 - loss: 0.0489 - val_accuracy: 0.9480 - val_loss: 0.2074\n",
      "Epoch 3/10\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 82ms/step - accuracy: 0.9999 - loss: 7.5714e-04 - val_accuracy: 0.9527 - val_loss: 0.2255\n",
      "Epoch 4/10\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 80ms/step - accuracy: 1.0000 - loss: 2.7923e-04 - val_accuracy: 0.9562 - val_loss: 0.2011\n",
      "Epoch 5/10\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 81ms/step - accuracy: 0.9765 - loss: 0.0866 - val_accuracy: 0.7068 - val_loss: 1.4037\n",
      "Epoch 6/10\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 75ms/step - accuracy: 0.9953 - loss: 0.0158 - val_accuracy: 0.9374 - val_loss: 0.1888\n",
      "Epoch 7/10\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 80ms/step - accuracy: 1.0000 - loss: 2.7333e-04 - val_accuracy: 0.9547 - val_loss: 0.1425\n",
      "Epoch 8/10\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 80ms/step - accuracy: 0.9947 - loss: 0.0183 - val_accuracy: 0.9134 - val_loss: 0.3419\n",
      "Epoch 9/10\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 81ms/step - accuracy: 0.9996 - loss: 0.0016 - val_accuracy: 0.9080 - val_loss: 0.3268\n",
      "Epoch 10/10\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 76ms/step - accuracy: 0.9966 - loss: 0.0104 - val_accuracy: 0.9366 - val_loss: 0.2316\n"
     ]
    }
   ],
   "source": [
    "# Build Sign Language Detection Model\n",
    "model_sign = tf.keras.Sequential([\n",
    "    tf.keras.layers.InputLayer(input_shape=(28, 28, 1)),\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(24, activation='softmax')\n",
    "])\n",
    "\n",
    "model_sign.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model_sign.fit(X_train_sign, y_train_sign, epochs=10, batch_size=32, validation_data=(X_test_sign, y_test_sign))\n",
    "\n",
    "# Build Emotion Detection FER Model\n",
    "model_fer = tf.keras.Sequential([\n",
    "    tf.keras.layers.InputLayer(input_shape=(48, 48, 1)),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(256, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(1024, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(7, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "47e607b4-ab9b-4113-b8d5-0461f6fe1af8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 1s/step - accuracy: 0.3780 - loss: 1.6228 - val_accuracy: 0.3068 - val_loss: 1.7830 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 716ms/step - accuracy: 0.5248 - loss: 1.2559 - val_accuracy: 0.4781 - val_loss: 1.3669 - learning_rate: 8.9125e-04\n",
      "Epoch 3/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 348ms/step - accuracy: 0.5829 - loss: 1.1026 - val_accuracy: 0.5673 - val_loss: 1.1573 - learning_rate: 7.9433e-04\n",
      "Epoch 4/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 358ms/step - accuracy: 0.6378 - loss: 0.9670 - val_accuracy: 0.5135 - val_loss: 1.3783 - learning_rate: 7.0795e-04\n",
      "Epoch 5/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 376ms/step - accuracy: 0.6919 - loss: 0.8239 - val_accuracy: 0.5620 - val_loss: 1.2215 - learning_rate: 6.3096e-04\n",
      "Epoch 6/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 374ms/step - accuracy: 0.7484 - loss: 0.6786 - val_accuracy: 0.5743 - val_loss: 1.2417 - learning_rate: 5.6234e-04\n",
      "Epoch 7/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 371ms/step - accuracy: 0.8125 - loss: 0.5218 - val_accuracy: 0.5550 - val_loss: 1.4371 - learning_rate: 5.0119e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 376ms/step - accuracy: 0.8654 - loss: 0.3777 - val_accuracy: 0.5648 - val_loss: 1.5574 - learning_rate: 4.4668e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 379ms/step - accuracy: 0.9105 - loss: 0.2581 - val_accuracy: 0.5787 - val_loss: 1.7189 - learning_rate: 3.9811e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 382ms/step - accuracy: 0.9421 - loss: 0.1700 - val_accuracy: 0.5751 - val_loss: 1.9239 - learning_rate: 3.5481e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 373ms/step - accuracy: 0.9606 - loss: 0.1208 - val_accuracy: 0.5748 - val_loss: 2.1861 - learning_rate: 3.1623e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 373ms/step - accuracy: 0.9726 - loss: 0.0902 - val_accuracy: 0.5743 - val_loss: 2.4335 - learning_rate: 2.8184e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 376ms/step - accuracy: 0.9824 - loss: 0.0573 - val_accuracy: 0.5754 - val_loss: 2.4952 - learning_rate: 2.5119e-04\n",
      "Epoch 13: early stopping\n",
      "Epoch 1/10\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 11ms/step - accuracy: 0.9997 - loss: 0.0021\n",
      "Epoch 2/10\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.9938 - loss: 0.0246\n",
      "Epoch 3/10\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.9990 - loss: 0.0035\n",
      "Epoch 4/10\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.9994 - loss: 0.0012\n",
      "Epoch 5/10\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.9982 - loss: 0.0071\n",
      "Epoch 6/10\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.9991 - loss: 0.0030\n",
      "Epoch 7/10\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.9983 - loss: 0.0069\n",
      "Epoch 8/10\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.9993 - loss: 0.0020\n",
      "Epoch 9/10\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.9999 - loss: 8.5703e-04\n",
      "Epoch 10/10\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.9963 - loss: 0.0172\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.5772 - loss: 2.4966\n",
      "compile_metrics: 57.54%\n"
     ]
    }
   ],
   "source": [
    "model_fer.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Define data augmentation\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    tf.keras.layers.RandomFlip('horizontal'),\n",
    "    tf.keras.layers.RandomRotation(0.2),\n",
    "    tf.keras.layers.RandomZoom(0.2)\n",
    "])\n",
    "\n",
    "# Apply data augmentation to the training data\n",
    "x_train_fer_aug = data_augmentation(x_train_fer)\n",
    "y_train_fer_aug = y_train_fer\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, verbose=1)\n",
    "lr_schedule = tf.keras.callbacks.LearningRateScheduler(lambda epochs: 1e-3 * 10**(-epochs/20))\n",
    "    \n",
    "model_fer.fit(x_train_fer, y_train_fer, batch_size=128, epochs=50, validation_data=(x_test_fer, y_test_fer), shuffle=True, callbacks=[early_stopping, lr_schedule])\n",
    "\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(np.argmax(y_train_sign, axis=1)),\n",
    "    y=np.argmax(y_train_sign, axis=1)\n",
    ")\n",
    "\n",
    "class_weights_dict = dict(enumerate(class_weights))\n",
    "\n",
    "model_sign.fit(X_train_sign, y_train_sign, epochs=10, class_weight=class_weights_dict)\n",
    "\n",
    "model_fer.save_weights(r\"D:\\MCA project\\Extra Projects\\fer2013_new.weights.h5\")\n",
    "model_fer.load_weights(r\"D:\\MCA project\\Extra Projects\\fer2013_new.weights.h5\")\n",
    "\n",
    "# Evaluate the model\n",
    "score = model_fer.evaluate(x_test_fer, y_test_fer)\n",
    "print('%s: %.2f%%' % (model_fer.metrics_names[1], score[1] * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "86f48204-eb4f-411b-8166-955e74a6bf7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> testing image index: 754\n",
      "> true emotion: netural\n",
      "> predicted emotion: netural\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sign_labels = [chr(i) for i in range(65, 65+24)]\n",
    "emotion_labels = ['angry', 'disgust', 'fearful', 'happy', 'sad', 'surprise', 'netural']\n",
    "\n",
    "\n",
    "# Update the testing output\n",
    "img_index = np.random.randint(x_test_fer.shape[0])\n",
    "sample_img = x_test_fer[img_index]\n",
    "pred_cls_fer = np.argmax(model_fer.predict(sample_img.reshape(1, 48, 48, 1), verbose=0))\n",
    "true_cls_fer = np.argmax(y_test_fer[img_index])\n",
    "print(f'> testing image index: {img_index}\\n> true emotion: {emotion_labels[true_cls_fer]}\\n> predicted emotion: {emotion_labels[pred_cls_fer]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5b3491da-45ed-493d-b313-98b788d795a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing functions for frames\n",
    "def preprocess_frame(frame, size):\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    frame = cv2.resize(frame, size) / 255.0\n",
    "    return np.expand_dims(frame, axis=-1)\n",
    "\n",
    "def get_prediction(frame, model, size):\n",
    "    preprocessed_frame = preprocess_frame(frame, size)\n",
    "    prediction = model.predict(np.expand_dims(preprocessed_frame, axis=0), verbose=0)\n",
    "    return np.argmax(prediction)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0b019a79-987e-4887-abc7-39ebe9b2df81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Capture Video\n",
    "cap = cv2.VideoCapture(0, cv2.CAP_DSHOW)\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "cap.set(cv2.CAP_PROP_FPS, 30)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open video capture.\")\n",
    "    exit()\n",
    "\n",
    "\n",
    "# Update real-time video display\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Error: Could not read frame.\")\n",
    "        break\n",
    "\n",
    "    sign_prediction = get_prediction(frame, model_sign, (28, 28))\n",
    "    emotion_prediction = get_prediction(frame, model_fer, (48, 48))\n",
    "\n",
    "    cv2.rectangle(frame, (10, 10), (250, 100), (0, 0, 0), -1)\n",
    "    cv2.putText(frame, f\"Sign: {sign_labels[sign_prediction]}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)\n",
    "    cv2.putText(frame, f\"Emotion: {emotion_labels[emotion_prediction]}\", (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)\n",
    "\n",
    "    cv2.imshow('Sign Language and Emotion Detection', frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
